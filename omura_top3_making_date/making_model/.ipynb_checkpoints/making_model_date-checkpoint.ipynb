{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dateや季節のデータを持ったデータを取得したのでそれに合わせて\n",
    "###   モデルのパラメータを探索的に求める。\n",
    "# ダミー変換に手を加えたトレインデータ作成\n",
    "#### ゴール:従来のトレーンデータに月、大会の日数、大会の何日目か、季節の情報をダミー化して追加したカラムの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "from imblearn.under_sampling import RandomUnderSampler #アンダーサンプリング用\n",
    "import pickle\n",
    "# 機械学習用\n",
    "from sklearn.cluster import KMeans #クラスタリング用\n",
    "from sklearn.ensemble import RandomForestClassifier#ランダムフォレスト\n",
    "from copy import deepcopy as cp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "pd.set_option('display.width',400)#勝手に改行コードを入れられるのを防ぐ\n",
    "place='omura'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_PCA_df(PCA_arr):#PCAで削減したものは二次元配列で帰ってくるので、それをデータフレームにして返す関数\n",
    "    X=[0]*len(PCA_arr)\n",
    "    Y=[0]*len(PCA_arr)\n",
    "    index=0\n",
    "    for arr in PCA_arr:\n",
    "        X[index]=arr[0]\n",
    "        Y[index]=arr[1]\n",
    "        index+=1\n",
    "    return pd.DataFrame({'X':X,'Y':Y})\n",
    "\n",
    "def making_pred_df(df):#配当金、着の情報は切りぬかなくてもうまいことやってくれる。\n",
    "    pred_race_df=df\n",
    "    #pred_race_df=pred_race_df.drop([\"Unnamed: 0\"],axis=1)#csvファイルについている名無しの列を削除\n",
    "    result_df=pred_race_df\n",
    "    result_df=result_df.drop([\"racer_1_ID\",\"racer_2_ID\",\"racer_3_ID\",\"racer_4_ID\",\"racer_5_ID\",\"racer_6_ID\",],axis=1)#IDはいらないので削除\n",
    "    result_df=result_df.replace(0.0000,{\"racer_1_ave_st_time\":0.22})#新人のave_st_timeを0.22に\n",
    "    result_df=result_df.replace(0.0000,{\"racer_2_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_3_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_4_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_5_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_6_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_1_doub_win\":0.02})#新人の着に絡む確率ave_st_timeを0.02に(新人の半期の偏差から導出)\n",
    "    result_df=result_df.replace(0.0000,{\"racer_2_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_3_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_4_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_5_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_6_doub_win\":0.02})\n",
    "    #配当金と結果の情報を横によけておく。(仮のデータフレームに格納する）=========================================================\n",
    "    #クラスタリングに使わないカラムを取り除く\n",
    "    drop_col_names=['result_com','money']\n",
    "    train_drops_df=pd.DataFrame(columns=drop_col_names)\n",
    "    train_drops_df['result_com']=result_df['result_com']\n",
    "    train_drops_df['money']=result_df['money']\n",
    "    result_df=result_df.drop(drop_col_names,axis=1)\n",
    "    #==============================================================================================================================\n",
    "    #ダミー変数化\n",
    "    #月をダミー化\n",
    "    empty_arr=[0]*len(result_df)\n",
    "    for number in np.arange(1,13,1):\n",
    "        result_df['month_{}'.format(int(number))]=empty_arr\n",
    "    dummie_df=pd.get_dummies(result_df['month'])#月をダミー化\n",
    "    for column, val in dummie_df.iteritems():\n",
    "        result_df['month_{}'.format(int(column))]=val\n",
    "\n",
    "        \n",
    "    #季節のダミー化   \n",
    "    empty_arr=[0]*len(result_df)\n",
    "    seasons=['sp','su','au','wi']\n",
    "    for season in seasons:\n",
    "        result_df['{}'.format(number)]=empty_arr\n",
    "    dummie_df=pd.get_dummies(result_df['season'])#季節をダミー化\n",
    "    for column, val in dummie_df.iteritems():\n",
    "        result_df['{}'.format(column)]=val\n",
    "\n",
    "\n",
    "    #開催日数のダミー化\n",
    "    empty_arr=[0]*len(result_df)\n",
    "    ranges=[1,2,3,4,5,6,7]#年末がおかしくなるっぽいから、一応からむだけ作っておく　\n",
    "    for number in ranges:\n",
    "        result_df['range_{}'.format(int(number))]=empty_arr\n",
    "    dummie_df=pd.get_dummies(result_df['range_date'])#開催日数をダミー化\n",
    "    for column, val in dummie_df.iteritems():\n",
    "        result_df['range_{}'.format(int(column))]=val\n",
    "        \n",
    "    #開催日数のうちの何日目かのダミー化\n",
    "    empty_arr=[0]*len(result_df)\n",
    "    num_dates=[1,2,3,4,5,6,7]\n",
    "    for number in num_dates:\n",
    "        result_df['num_date_{}'.format(int(number))]=empty_arr\n",
    "    dummie_df=pd.get_dummies(result_df['num_date'])#開催日数をダミー化\n",
    "    for column, val in dummie_df.iteritems():\n",
    "        result_df['num_date_{}'.format(int(column))]=val\n",
    "        \n",
    "    result_df=result_df.drop(['month','season','range_date','num_date'],axis=1)#ダミー化し終わったカラムは削除する\n",
    "    #レース番号のダミー化===============================================\n",
    "    result_df_dummie=result_df\n",
    "    race_dummie_df=pd.get_dummies(result_df_dummie['number_race'])#number_raceをダミー化\n",
    "    for column, val in race_dummie_df.iteritems():\n",
    "        result_df_dummie['race_{}'.format(int(column))]=val\n",
    "    result_df_dummie=result_df_dummie.drop('number_race',axis=1)    \n",
    "    #===========================新規、性別の取り出し機能が良くなかったため作り直す\n",
    "    cols=list(result_df_dummie.columns)\n",
    "    male_cols=[s for s in cols if 'male' in s]#性別を示すカラムを取り出す\n",
    "    empty_arr=[0]*len(result_df_dummie)\n",
    "    for col in male_cols:\n",
    "        for number in np.arange(0,2,1):\n",
    "              result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
    "        male_dummie_df=pd.get_dummies(result_df_dummie[col])#性別をダミー化\n",
    "        for column, val in male_dummie_df.iteritems():\n",
    "              result_df_dummie['{}_{}'.format(col,int(column))]=val\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1)\n",
    "\n",
    "    cols=list(result_df_dummie.columns)\n",
    "    moter_cols=[s for s in cols if '_mo' in s]#モーター番号を示すカラムを取り出す\n",
    "    boat_cols=[s for s in cols if '_bo' in s]#ボート番号を示すカラムを取り出す\n",
    "    #boat もmoterも番号は1~99とする\n",
    "    numbers=np.arange(1, 100, 1)\n",
    "    empty_arr=[0]*len(result_df_dummie)\n",
    "    for col in moter_cols:\n",
    "        for number in numbers:\n",
    "              result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
    "        moter_dummie_df=pd.get_dummies(result_df_dummie[col])#モータ番号をダミー化\n",
    "        for column, val in moter_dummie_df.iteritems():\n",
    "              result_df_dummie['{}_{}'.format(col,int(column))]=val\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1)\n",
    "\n",
    "    #boat番号をダミー化\n",
    "    for col in boat_cols:\n",
    "        for number in numbers:\n",
    "              result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
    "        boat_dummie_df=pd.get_dummies(result_df_dummie[col])#boat番号をダミー化\n",
    "        for column, val in boat_dummie_df.iteritems():\n",
    "              result_df_dummie['{}_{}'.format(col,int(column))]=val\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1)\n",
    "    result_df=result_df_dummie\n",
    "\n",
    "    \"\"\"\n",
    "    #クラスタリング\n",
    "    #分けてみるクラスタの数は[8,10]の2個\n",
    "    #cluster_target_df　　trainのデータからリザルトと配当金を取り除いたもの\n",
    "    target_num_cluster=[8,10]\n",
    "    #test_clustaring_df=train_has_PCA_df\n",
    "    clustar_target_df=result_df\n",
    "    clustaring_df=clustar_target_df\n",
    "    for num_cluster in target_num_cluster:\n",
    "        pred = KMeans(random_state=1,n_clusters=num_cluster).fit_predict(clustar_target_df)\n",
    "        clustaring_df['num={}'.format(num_cluster)]=pred\n",
    "    \"\"\"\n",
    "    result_df['result_com']=train_drops_df['result_com']#正解ラベルを戻してあげる\n",
    "    result_df['money']=train_drops_df['money']#配当金を戻してあげる\n",
    "    model_df=result_df\n",
    "\n",
    "    return model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['day'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2818d8b909aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Unnamed: 0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mresult_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'day'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#現状使わないカラムは削除する\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdate_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'month'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'num_date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'range_date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'season'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nabe0\\desktop\\nabepy\\env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4115\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4116\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4117\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4118\u001b[0m         )\n\u001b[0;32m   4119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nabe0\\desktop\\nabepy\\env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3912\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3913\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3914\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3916\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nabe0\\desktop\\nabepy\\env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3944\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3945\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3946\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3947\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nabe0\\desktop\\nabepy\\env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5338\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5339\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5340\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not found in axis\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5341\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5342\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['day'] not found in axis\""
     ]
    }
   ],
   "source": [
    "result_df=pd.read_csv('../csv/train_{}_date.csv'.format(place),encoding='utf-8')\n",
    "result_df=result_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "\n",
    "result_df=result_df.drop(['date','day'],axis=1)#現状使わないカラムは削除する\n",
    "\n",
    "date_cols=['year','month','num_date','range_date','season']\n",
    "date_df=pd.DataFrame(index=result_df.index)\n",
    "for col in date_cols:\n",
    "    date_df[col]=result_df[col]\n",
    "result_df=result_df.drop('year',axis=1)#yearカラムはデータの切り抜きで使うが学習では使わないがので削除（関数内でdropされないから）\n",
    "#result_df=result_df.drop(col,axis=1)\n",
    "#money_col=result_df['money']\n",
    "#result_df=result_df.drop('money',axis=1)#配当金情報の削除\n",
    "#result_col=result_df['result_com']\n",
    "#result_df=result_df.drop('result_com',axis=1)#着の組み合わせ\n",
    "result_df=making_pred_df(result_df)#モデルに突っ込むだけの状態に加工（新人選手の情報、欠損地加工とダミー化）\n",
    "#result_df.to_csv('train_df.csv')\n",
    "df=result_df\n",
    "### 学習データのベースを作成(validとtrainに分割)\n",
    "#学習、テストデータ切り分け(2019,2020のデータを検証用データに、ほかは学習)\n",
    "df['year']=date_df['year']\n",
    "valid_df = df[(df['year']==2019) | ((df['year']==2020) )]#2019,2020のデータを検証用データに。\n",
    "train_df =  df[(df['year']!=2019) & ((df['year']!=2020) )]#そのほかを学習データに\n",
    "#学習データを切り分けたらyearはいらないから削除する\n",
    "valid_df=valid_df.drop(['year'],axis=1)\n",
    "train_df=train_df.drop(['year'],axis=1)\n",
    "\n",
    "train_money=pd.Series(train_df['money'])\n",
    "valid_money=pd.Series(valid_df['money'])\n",
    "valid_total_df=valid_df.copy()#あとで分析用に全部のまとめ先のDf\n",
    "train_total_df=train_df.copy()#あとで分析用に全部のまとめ先のDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モデルの性能評価用のデータフレーム (モデルを使うかを判断する閾値を収納する)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#出現数の分布\n",
    "result_com_s=valid_df['result_com'].value_counts()\n",
    "result_com_s=result_com_s.sort_index()\n",
    "gain_mean=valid_df.groupby('result_com')['money'].mean()\n",
    "gain_mean=gain_mean.sort_index()\n",
    "\n",
    "gain_median=valid_df.groupby('result_com')['money'].median()\n",
    "gain_median=gain_median.sort_index()\n",
    "result_com_df=pd.DataFrame({'result_com':result_com_s.index,\n",
    "                            'result_com_num':result_com_s.values,\n",
    "                            'result_com_per':result_com_s.values/sum(result_com_s.values)*100,\n",
    "                            'gain_mean':gain_mean.values,\n",
    "                            'gain_median':gain_median.values,})\n",
    "result_com_df=result_com_df.iloc[0:28]#探索的に探すにも最後のほうは役にモデルなのはわかっているため\n",
    "result_com_df\n",
    "#result_com_df=result_com_df.set_index('result_com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデリング(探索的にパラメータを決める)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_com=1\n",
    "#depth=5\n",
    "model_score_df=pd.DataFrame(columns=['target_com','depth','target_per','総収益', '投資金額','出現数','購買予測数','利益率','購買的中率','的中数'])\n",
    "for result_com_number in result_com_df['result_com'].values:\n",
    "    print(result_com_number)\n",
    "    result_com=result_com_number\n",
    "    #result_comごとの閾値の決定========================================================================\n",
    "    \n",
    "    gain_th=10#利益率の閾値\n",
    "    result_s=result_com_df[result_com_df['result_com']==result_com]\n",
    "    buy_accuracy_th=result_s['result_com_per'].values[0]*1.1#買ったうちの的中率の閾値\n",
    "    num_tp_th=result_s['result_com_num'].values[0]*0.2#あたった回数の閾値(出現回数の20%が的中)\n",
    "    #===============================================================================\n",
    "    #学習データのラベル変換==========================================================\n",
    "    result_train_df=train_df.copy() \n",
    "    result_arr=[0]*len(result_train_df)\n",
    "    i=0\n",
    "    for result in result_train_df['result_com']:\n",
    "        if ((result==result_com)):\n",
    "            result_arr[i]=1\n",
    "        else:\n",
    "            result_arr[i]=0\n",
    "        i+=1\n",
    "    result_train_df['result_com']=result_arr\n",
    "    result_valid_df=valid_df.copy() \n",
    "    result_arr=[0]*len(result_valid_df)\n",
    "    i=0\n",
    "    for result in result_valid_df['result_com']:\n",
    "        if ((result==result_com)):\n",
    "            result_arr[i]=1\n",
    "        else:\n",
    "            result_arr[i]=0\n",
    "        i+=1\n",
    "\n",
    "    result_valid_df['result_com']=result_arr\n",
    "\n",
    "    result_train_df['money']=train_money\n",
    "    result_valid_df['money']=valid_money\n",
    "    #学習データラベル変換終わり============================================\n",
    "\n",
    "    for_arr=np.arange(1,100,1)\n",
    "    accuracy_arr=[0]*len(for_arr)\n",
    "    target_per_arr=[0]*len(for_arr)\n",
    "    pred_0=[0]*len(for_arr)\n",
    "    gain_arr=[0]*len(for_arr)\n",
    "    model_gain_arr=[0]*len(result_valid_df)\n",
    "    valid_gain_arr=valid_money.values\n",
    "\n",
    "    depths_arr=[4,5,6,7,8]\n",
    "    for depth in depths_arr:\n",
    "        for sum_target_per in tqdm(for_arr):\n",
    "            \n",
    "            index=sum_target_per-1\n",
    "            target_per=50+sum_target_per\n",
    "            target_per_arr[index]=target_per\n",
    "\n",
    "            #モデルの評価指標値を格納するseries======================\n",
    "            model_score_s=pd.Series(index=['target_com','depth','target_per','総収益', '投資金額','出現数','購買予測数','利益率','購買的中率','的中数'])\n",
    "            model_score_s['target_com']=result_com#目標としているresult_comラベル番号\n",
    "            model_score_s['depth']=depth#ハイパーパラメータ＿木の深さ\n",
    "            model_score_s['target_per']=target_per#学習データ_1に対してどの程度の0のデータを持たせるか。\n",
    "            #======================\n",
    "            #trainの[0]に対して、target_perの割合の量[1]を持った学習データの作成\n",
    "            # 一層目の判別機のtrainデータ　:terget_result_df\n",
    "            target_df=result_train_df#ベースのデータフレームをコピー\n",
    "            target_df=target_df.sample(frac=1, random_state=1)#シャッフル、時系列の偏りを無くす\n",
    "            target_1_df=target_df[target_df['result_com']==1]\n",
    "            len_1=len(target_1_df)\n",
    "            target_0_df=target_df[target_df['result_com']==0]\n",
    "            len_0=len(target_0_df)\n",
    "            target_0_df=target_0_df.iloc[(len_0-int(len_1*(target_per/100))):len_0]#1に対する目標の割合ぶん0の結果だったレースを抽出（後ろから抽出）\n",
    "            target_train_df=pd.concat([target_1_df, target_0_df])\n",
    "            #以下学習パート======================================================\n",
    "            target_x_train=target_train_df.drop('money',axis=1)\n",
    "            target_x_train=target_x_train.drop('result_com',axis=1)\n",
    "            target_y_train=target_train_df['result_com']\n",
    "            #テストデータ\n",
    "            target_y_valid=result_valid_df['result_com']\n",
    "            target_x_valid=result_valid_df.drop('money',axis=1)\n",
    "            target_x_valid=target_x_valid.drop('result_com',axis=1)\n",
    "            RF = RandomForestClassifier(random_state=1,n_estimators=1000,max_depth=depth)\n",
    "            RF = RF.fit(target_x_train,target_y_train)\n",
    "\n",
    "\n",
    "            #以下精度検証(１の正答率のみ調査)\n",
    "\n",
    "            # 未知データに対する予測値\n",
    "            predict_y_valid = RF.predict(target_x_valid)\n",
    "\n",
    "            #[1]の正答率を見る\n",
    "            pred_valid_df=pd.DataFrame({'pred':predict_y_valid\n",
    "                                      , 'valid':target_y_valid})\n",
    "            num_1=len(pred_valid_df[pred_valid_df['valid']==1])\n",
    "            count=0\n",
    "            #追加　配当金の情報も考慮する。\n",
    "            gain_index=0\n",
    "            model_gain_arr=[0]*len(result_valid_df)\n",
    "            for _, s in pred_valid_df.iterrows():\n",
    "                if ((s['pred']==1) and (s['valid']==1)):\n",
    "                    count+=1#的中回数\n",
    "                    model_gain_arr[gain_index]=valid_gain_arr[gain_index]\n",
    "                gain_index+=1\n",
    "            #print('test accyracy: {}'.format((count/num_1)*100))\n",
    "            gain_arr[index]=sum(model_gain_arr)\n",
    "            accuracy_arr[index]=(count/num_1)*100\n",
    "            try:\n",
    "                pred_0[index]=pred_valid_df['pred'].value_counts()[0]\n",
    "            except:\n",
    "                pred_0[index]=0\n",
    "            #scoreのseriesに情報書き込み==================\n",
    "            model_score_s['総収益']=sum(model_gain_arr)\n",
    "            model_score_s['投資金額']=100*sum(predict_y_valid)\n",
    "            model_score_s['出現数']=sum(target_y_valid)\n",
    "            model_score_s['購買予測数']=sum(predict_y_valid)\n",
    "            model_score_s['利益率']=(model_score_s['総収益']/model_score_s['投資金額'])*100\n",
    "            model_score_s['購買的中率']=(count/sum(predict_y_valid))*100\n",
    "            model_score_s['的中数']=count\n",
    "            model_score_df=model_score_df.append(model_score_s,ignore_index=True)\n",
    "            \n",
    "#モデルの「スコアを保存        \n",
    "model_score_df.to_csv('../csv/model_score_date_{}.csv'.format(place), encoding='utf_8_sig')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルのスコアを保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_score_df.to_csv('model_score.csv', encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデリング用＿動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nresult_com=1\\ndepth=5\\nmodel_score_df=pd.DataFrame(columns=['target_com','depth','target_per','総収益', '投資金額','出現数','購買予測数','利益率','購買的中率','的中数'])\\n\\n#result_comごとの閾値の決定========================================================================\\ngain_th=10#利益率の閾値\\nresult_s=result_com_df[result_com_df['result_com']==result_com]\\nbuy_accuracy_th=result_s['result_com_per'].values[0]*1.1#買ったうちの的中率の閾値\\nnum_tp_th=result_s['result_com_num'].values[0]*0.2#あたった回数の閾値(出現回数の20%が的中)\\n#===============================================================================\\n#学習データのラベル変換==========================================================\\nresult_train_df=train_df\\nresult_arr=[0]*len(result_train_df)\\ni=0\\nfor result in result_train_df['result_com']:\\n    if ((result==result_com)):\\n        result_arr[i]=1\\n    else:\\n        result_arr[i]=0\\n    i+=1\\nresult_train_df['result_com']=result_arr\\n\\nresult_valid_df=valid_df\\nresult_arr=[0]*len(result_valid_df)\\ni=0\\nfor result in result_valid_df['result_com']:\\n    if ((result==result_com)):\\n        result_arr[i]=1\\n    else:\\n        result_arr[i]=0\\n    i+=1\\n\\nresult_valid_df['result_com']=result_arr\\n\\nresult_train_df['money']=train_money\\nresult_valid_df['money']=valid_money\\n#学習データラベル変換終わり============================================\\n\\nfor_arr=np.arange(1,100,1)\\naccuracy_arr=[0]*len(for_arr)\\ntarget_per_arr=[0]*len(for_arr)\\npred_0=[0]*len(for_arr)\\ngain_arr=[0]*len(for_arr)\\nmodel_gain_arr=[0]*len(result_valid_df)\\nvalid_gain_arr=valid_money.values\\nfor sum_target_per in for_arr:\\n    \\n    index=sum_target_per-1\\n    target_per=50+sum_target_per\\n    target_per_arr[index]=target_per\\n    \\n    #モデルの評価指標値を格納するseries======================\\n    model_score_s=pd.Series(index=['target_com','depth','target_per','総収益', '投資金額','出現数','購買予測数','利益率','購買的中率','的中数'])\\n    model_score_s['target_com']=result_com#目標としているresult_comラベル番号\\n    model_score_s['depth']=depth#ハイパーパラメータ＿木の深さ\\n    model_score_s['target_per']=target_per#学習データ_1に対してどの程度の0のデータを持たせるか。\\n    #======================\\n    #trainの[0]に対して、target_perの割合の量[1]を持った学習データの作成\\n    # 一層目の判別機のtrainデータ\\u3000:terget_result_df\\n    target_df=result_train_df#ベースのデータフレームをコピー\\n    target_df=target_df.sample(frac=1, random_state=1)#シャッフル、時系列の偏りを無くす\\n    target_1_df=target_df[target_df['result_com']==1]\\n    len_1=len(target_1_df)\\n    target_0_df=target_df[target_df['result_com']==0]\\n    len_0=len(target_0_df)\\n    target_0_df=target_0_df.iloc[(len_0-int(len_1*(target_per/100))):len_0]#1に対する目標の割合ぶん0の結果だったレースを抽出（後ろから抽出）\\n    target_train_df=pd.concat([target_1_df, target_0_df])\\n    #以下学習パート======================================================\\n    target_x_train=target_train_df.drop('money',axis=1)\\n    target_x_train=target_x_train.drop('result_com',axis=1)\\n    target_y_train=target_train_df['result_com']\\n    #テストデータ\\n    target_y_valid=result_valid_df['result_com']\\n    target_x_valid=result_valid_df.drop('money',axis=1)\\n    target_x_valid=target_x_valid.drop('result_com',axis=1)\\n    RF = RandomForestClassifier(random_state=1,n_estimators=1000,max_depth=depth)\\n    RF = RF.fit(target_x_train,target_y_train)\\n\\n\\n    #以下精度検証(１の正答率のみ調査)\\n\\n    # 未知データに対する予測値\\n    predict_y_valid = RF.predict(target_x_valid)\\n\\n    #[1]の正答率を見る\\n    pred_valid_df=pd.DataFrame({'pred':predict_y_valid\\n                              , 'valid':target_y_valid})\\n    num_1=len(pred_valid_df[pred_valid_df['valid']==1])\\n    count=0\\n    #追加\\u3000配当金の情報も考慮する。\\n    gain_index=0\\n    model_gain_arr=[0]*len(result_valid_df)\\n    for _, s in pred_valid_df.iterrows():\\n        if ((s['pred']==1) and (s['valid']==1)):\\n            count+=1#的中回数\\n            model_gain_arr[gain_index]=valid_gain_arr[gain_index]\\n        gain_index+=1\\n    #print('test accyracy: {}'.format((count/num_1)*100))\\n    gain_arr[index]=sum(model_gain_arr)\\n    accuracy_arr[index]=(count/num_1)*100\\n    try:\\n        pred_0[index]=pred_valid_df['pred'].value_counts()[0]\\n    except:\\n        pred_0[index]=0\\n    #scoreのseriesに情報書き込み==================\\n    model_score_s['総収益']=sum(model_gain_arr)\\n    model_score_s['投資金額']=100*sum(predict_y_valid)\\n    model_score_s['出現数']=sum(target_y_valid)\\n    model_score_s['購買予測数']=sum(predict_y_valid)\\n    model_score_s['利益率']=(model_score_s['総収益']/model_score_s['投資金額'])*100\\n    model_score_s['購買的中率']=(count/sum(predict_y_valid))*100\\n    model_score_s['的中数']=count\\n    model_score_df=model_score_df.append(model_score_s,ignore_index=True)\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "result_com=1\n",
    "depth=5\n",
    "model_score_df=pd.DataFrame(columns=['target_com','depth','target_per','総収益', '投資金額','出現数','購買予測数','利益率','購買的中率','的中数'])\n",
    "\n",
    "#result_comごとの閾値の決定========================================================================\n",
    "gain_th=10#利益率の閾値\n",
    "result_s=result_com_df[result_com_df['result_com']==result_com]\n",
    "buy_accuracy_th=result_s['result_com_per'].values[0]*1.1#買ったうちの的中率の閾値\n",
    "num_tp_th=result_s['result_com_num'].values[0]*0.2#あたった回数の閾値(出現回数の20%が的中)\n",
    "#===============================================================================\n",
    "#学習データのラベル変換==========================================================\n",
    "result_train_df=train_df\n",
    "result_arr=[0]*len(result_train_df)\n",
    "i=0\n",
    "for result in result_train_df['result_com']:\n",
    "    if ((result==result_com)):\n",
    "        result_arr[i]=1\n",
    "    else:\n",
    "        result_arr[i]=0\n",
    "    i+=1\n",
    "result_train_df['result_com']=result_arr\n",
    "\n",
    "result_valid_df=valid_df\n",
    "result_arr=[0]*len(result_valid_df)\n",
    "i=0\n",
    "for result in result_valid_df['result_com']:\n",
    "    if ((result==result_com)):\n",
    "        result_arr[i]=1\n",
    "    else:\n",
    "        result_arr[i]=0\n",
    "    i+=1\n",
    "\n",
    "result_valid_df['result_com']=result_arr\n",
    "\n",
    "result_train_df['money']=train_money\n",
    "result_valid_df['money']=valid_money\n",
    "#学習データラベル変換終わり============================================\n",
    "\n",
    "for_arr=np.arange(1,100,1)\n",
    "accuracy_arr=[0]*len(for_arr)\n",
    "target_per_arr=[0]*len(for_arr)\n",
    "pred_0=[0]*len(for_arr)\n",
    "gain_arr=[0]*len(for_arr)\n",
    "model_gain_arr=[0]*len(result_valid_df)\n",
    "valid_gain_arr=valid_money.values\n",
    "for sum_target_per in for_arr:\n",
    "    \n",
    "    index=sum_target_per-1\n",
    "    target_per=50+sum_target_per\n",
    "    target_per_arr[index]=target_per\n",
    "    \n",
    "    #モデルの評価指標値を格納するseries======================\n",
    "    model_score_s=pd.Series(index=['target_com','depth','target_per','総収益', '投資金額','出現数','購買予測数','利益率','購買的中率','的中数'])\n",
    "    model_score_s['target_com']=result_com#目標としているresult_comラベル番号\n",
    "    model_score_s['depth']=depth#ハイパーパラメータ＿木の深さ\n",
    "    model_score_s['target_per']=target_per#学習データ_1に対してどの程度の0のデータを持たせるか。\n",
    "    #======================\n",
    "    #trainの[0]に対して、target_perの割合の量[1]を持った学習データの作成\n",
    "    # 一層目の判別機のtrainデータ　:terget_result_df\n",
    "    target_df=result_train_df#ベースのデータフレームをコピー\n",
    "    target_df=target_df.sample(frac=1, random_state=1)#シャッフル、時系列の偏りを無くす\n",
    "    target_1_df=target_df[target_df['result_com']==1]\n",
    "    len_1=len(target_1_df)\n",
    "    target_0_df=target_df[target_df['result_com']==0]\n",
    "    len_0=len(target_0_df)\n",
    "    target_0_df=target_0_df.iloc[(len_0-int(len_1*(target_per/100))):len_0]#1に対する目標の割合ぶん0の結果だったレースを抽出（後ろから抽出）\n",
    "    target_train_df=pd.concat([target_1_df, target_0_df])\n",
    "    #以下学習パート======================================================\n",
    "    target_x_train=target_train_df.drop('money',axis=1)\n",
    "    target_x_train=target_x_train.drop('result_com',axis=1)\n",
    "    target_y_train=target_train_df['result_com']\n",
    "    #テストデータ\n",
    "    target_y_valid=result_valid_df['result_com']\n",
    "    target_x_valid=result_valid_df.drop('money',axis=1)\n",
    "    target_x_valid=target_x_valid.drop('result_com',axis=1)\n",
    "    RF = RandomForestClassifier(random_state=1,n_estimators=1000,max_depth=depth)\n",
    "    RF = RF.fit(target_x_train,target_y_train)\n",
    "\n",
    "\n",
    "    #以下精度検証(１の正答率のみ調査)\n",
    "\n",
    "    # 未知データに対する予測値\n",
    "    predict_y_valid = RF.predict(target_x_valid)\n",
    "\n",
    "    #[1]の正答率を見る\n",
    "    pred_valid_df=pd.DataFrame({'pred':predict_y_valid\n",
    "                              , 'valid':target_y_valid})\n",
    "    num_1=len(pred_valid_df[pred_valid_df['valid']==1])\n",
    "    count=0\n",
    "    #追加　配当金の情報も考慮する。\n",
    "    gain_index=0\n",
    "    model_gain_arr=[0]*len(result_valid_df)\n",
    "    for _, s in pred_valid_df.iterrows():\n",
    "        if ((s['pred']==1) and (s['valid']==1)):\n",
    "            count+=1#的中回数\n",
    "            model_gain_arr[gain_index]=valid_gain_arr[gain_index]\n",
    "        gain_index+=1\n",
    "    #print('test accyracy: {}'.format((count/num_1)*100))\n",
    "    gain_arr[index]=sum(model_gain_arr)\n",
    "    accuracy_arr[index]=(count/num_1)*100\n",
    "    try:\n",
    "        pred_0[index]=pred_valid_df['pred'].value_counts()[0]\n",
    "    except:\n",
    "        pred_0[index]=0\n",
    "    #scoreのseriesに情報書き込み==================\n",
    "    model_score_s['総収益']=sum(model_gain_arr)\n",
    "    model_score_s['投資金額']=100*sum(predict_y_valid)\n",
    "    model_score_s['出現数']=sum(target_y_valid)\n",
    "    model_score_s['購買予測数']=sum(predict_y_valid)\n",
    "    model_score_s['利益率']=(model_score_s['総収益']/model_score_s['投資金額'])*100\n",
    "    model_score_s['購買的中率']=(count/sum(predict_y_valid))*100\n",
    "    model_score_s['的中数']=count\n",
    "    model_score_df=model_score_df.append(model_score_s,ignore_index=True)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31600"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*sum(predict_y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128959.6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(model_gain_arr)/100*sum(predict_y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_com</th>\n",
       "      <th>depth</th>\n",
       "      <th>target_per</th>\n",
       "      <th>総収益</th>\n",
       "      <th>投資金額</th>\n",
       "      <th>出現数</th>\n",
       "      <th>購買予測数</th>\n",
       "      <th>利益率</th>\n",
       "      <th>購買的中率</th>\n",
       "      <th>的中数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4171.0</td>\n",
       "      <td>86.377368</td>\n",
       "      <td>7.839847</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>417000.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>86.398082</td>\n",
       "      <td>7.841727</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>416800.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4168.0</td>\n",
       "      <td>86.439539</td>\n",
       "      <td>7.845489</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>416500.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4165.0</td>\n",
       "      <td>86.501801</td>\n",
       "      <td>7.851140</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>416200.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4162.0</td>\n",
       "      <td>86.564152</td>\n",
       "      <td>7.856800</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>415800.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4158.0</td>\n",
       "      <td>86.647427</td>\n",
       "      <td>7.864358</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>414500.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4145.0</td>\n",
       "      <td>86.919180</td>\n",
       "      <td>7.889023</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>413700.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4137.0</td>\n",
       "      <td>87.087261</td>\n",
       "      <td>7.904278</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>360280.0</td>\n",
       "      <td>413000.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4130.0</td>\n",
       "      <td>87.234867</td>\n",
       "      <td>7.917676</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>358600.0</td>\n",
       "      <td>409300.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4093.0</td>\n",
       "      <td>87.612998</td>\n",
       "      <td>7.964818</td>\n",
       "      <td>326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>352980.0</td>\n",
       "      <td>405100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4051.0</td>\n",
       "      <td>87.134041</td>\n",
       "      <td>7.998025</td>\n",
       "      <td>324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>348980.0</td>\n",
       "      <td>402700.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4027.0</td>\n",
       "      <td>86.660045</td>\n",
       "      <td>8.020859</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>345160.0</td>\n",
       "      <td>395700.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>3957.0</td>\n",
       "      <td>87.227698</td>\n",
       "      <td>8.137478</td>\n",
       "      <td>322.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target_com  depth  target_per       総収益      投資金額    出現数   購買予測数        利益率     購買的中率    的中数\n",
       "0          1.0    4.0        51.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "1          1.0    4.0        52.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "2          1.0    4.0        53.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "3          1.0    4.0        54.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "4          1.0    4.0        55.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "5          1.0    4.0        56.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "6          1.0    4.0        57.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "7          1.0    4.0        58.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "8          1.0    4.0        59.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "9          1.0    4.0        60.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "10         1.0    4.0        61.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "11         1.0    4.0        62.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "12         1.0    4.0        63.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "13         1.0    4.0        64.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "14         1.0    4.0        65.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "15         1.0    4.0        66.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "16         1.0    4.0        67.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "17         1.0    4.0        68.0  360280.0  417100.0  327.0  4171.0  86.377368  7.839847  327.0\n",
       "18         1.0    4.0        69.0  360280.0  417000.0  327.0  4170.0  86.398082  7.841727  327.0\n",
       "19         1.0    4.0        70.0  360280.0  416800.0  327.0  4168.0  86.439539  7.845489  327.0\n",
       "20         1.0    4.0        71.0  360280.0  416500.0  327.0  4165.0  86.501801  7.851140  327.0\n",
       "21         1.0    4.0        72.0  360280.0  416200.0  327.0  4162.0  86.564152  7.856800  327.0\n",
       "22         1.0    4.0        73.0  360280.0  415800.0  327.0  4158.0  86.647427  7.864358  327.0\n",
       "23         1.0    4.0        74.0  360280.0  414500.0  327.0  4145.0  86.919180  7.889023  327.0\n",
       "24         1.0    4.0        75.0  360280.0  413700.0  327.0  4137.0  87.087261  7.904278  327.0\n",
       "25         1.0    4.0        76.0  360280.0  413000.0  327.0  4130.0  87.234867  7.917676  327.0\n",
       "26         1.0    4.0        77.0  358600.0  409300.0  327.0  4093.0  87.612998  7.964818  326.0\n",
       "27         1.0    4.0        78.0  352980.0  405100.0  327.0  4051.0  87.134041  7.998025  324.0\n",
       "28         1.0    4.0        79.0  348980.0  402700.0  327.0  4027.0  86.660045  8.020859  323.0\n",
       "29         1.0    4.0        80.0  345160.0  395700.0  327.0  3957.0  87.227698  8.137478  322.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score_df[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result_com</th>\n",
       "      <th>result_com_num</th>\n",
       "      <th>result_com_per</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>gain_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>0.455526</td>\n",
       "      <td>8726.315789</td>\n",
       "      <td>4390.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    result_com  result_com_num  result_com_per    gain_mean  gain_median\n",
       "27          28              19        0.455526  8726.315789       4390.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
